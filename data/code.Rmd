## Đọc dữ liệu
```{r}
library(dplyr)
library(tidyr)
library(rmarkdown)
library(ggplot2)

old_data <- read.csv("usa.csv")
paged_table(old_data) # thay thế cho print, in ra bảng đẹp hơn
```
## Làm sạch dữ liệu (Data cleaning)
Ta bỏ cột index và cột location vì location luôn cố định (USA).
```{r}
new_data <- old_data %>% select(3:14)
paged_table(new_data)
```
### Trích xuất các dữ liệu chính
(Chỉ giữ lại các cột cần thiết, bao gồm 6 cột của biến dự đoán và cột biến ước lượng)
```{r}
main_data <- subset(new_data , select = c(new_deaths , new_cases , new_tests, hosp_patients , positive_rate))
# paged_table(main_data)
```
### Xử lý dữ liệu khuyết (NA)

Ta tiến hành kiểm tra xem số lượng/tỉ lệ dữ liệu khuyết của mỗi thuộc tính là bao nhiêu. Nguyên nhân xuất hiện dữ liệu khuyết có thể xuất phát từ nhiều yếu tố, điển hình nhất là thiếu sót trong việc thu thập dữ liệu ngoài thực tế và nguồn tiếp cận dữ liệu bị hạn chế.

```{r}
main_data %>% sapply(function(col) sum(is.na(col)))    #Số dữ liệu bị khuyết theo cột
apply(main_data, 2, function(x)sum(is.na(x))/length(x))    #Tỉ lệ dữ liệu bị khuyết
```
Tỉ lệ dữ liệu khuyết tương đối cao, nếu chỉ đơn giản thay các giá trị NA bằng 0 thì kết quả thống kê sẽ bị ảnh hưởng rất nhiều. Để an toàn, ta sẽ loại bỏ hẳn các hàng có chứa ít nhất một dữ liệu khuyết.

```{r}
main_data <- na.omit(main_data)
# main_data[is.na(main_data)] <- 0    #NA <- 0
paged_table(main_data)
```

## Làm rõ dữ liệu

### Thống kê đơn biến
Thực hiện các phương pháp thống kê đơn biến lên từng biến dự đoán, 1 vài phương pháp: Summary Statistics, Frequency Distribution Table, Bar chart, Histogram... 

#### Summary Statistics
Ta tính các gía trị thống kê mô tả cho mỗi biến, bao gồm: trung bình (mean), trung vị (median), độ lệch chuẩn (sd), min, max

```{r}
stat_table<-apply(main_data[,c("new_deaths", "new_cases", "new_tests", "hosp_patients", "positive_rate")], 2,
function(x){c(mean(x), median(x), sd(x), min(x), max(x))})
rownames(stat_table)<-c("mean", "median", "sd", "min", "max")
paged_table(as.data.frame(stat_table))
```

Dựa vào biểu đồ, ta nhận thấy giá trị của chúng bị lệch khá nhiều và không tuân theo phân phối chuẩn. Vì thế, ta thực hiện transform dữ liệu bằng hàm logarithm, với hi vọng là dữ liệu sau khi transform sẽ tuân theo phân phối chuẩn:

```{r}
plot_hist_norm <- function(data, var) {
  # Calculate the variable to plot
  plot_var <- data[[var]]
  par(mfrow = c(1, 2))
  # Histogram of the variable
  # Normal curve overlay
  hist(plot_var, main = paste0(var), xlab = "x",
     col = "blue", border = "white", breaks = 20, freq = FALSE)
  hist(log(plot_var), main = paste0("Log(", var, ")"), xlab = "ln(x)",
     col = "blue", border = "white", breaks = 20, freq = FALSE)
  curve(dnorm(x, mean = mean(log(plot_var)), sd = sd(log(plot_var))), 
        col = "red", lwd = 2, add = TRUE) 
}
for (col_name in colnames(main_data)) {
  # Call plot_hist_norm on each column
  plot_hist_norm(main_data, col_name)
}
```

Rõ ràng biểu đồ sau khi chuyển đổi dữ liệu có hình dạng giống phân phối chuẩn hơn. Vì thế, ta sẽ sử dụng bộ dữ liệu sau khi chuyển đổi:

```{r}
# Apply log data transformation to all variables
for (col_name in colnames(main_data)) {
  main_data[[col_name]] <- log(main_data[[col_name]])
}

stat_table<-apply(main_data[,c("new_deaths", "new_cases", "new_tests", "hosp_patients", "positive_rate")], 2,
function(x){c(mean(x), median(x), sd(x), min(x), max(x))})
rownames(stat_table)<-c("mean", "median", "sd", "min", "max")
paged_table(as.data.frame(stat_table))
```

### Thống kê đa biến

Ta tính ma trận hiệp phương sai của cả 7 biến này để kiểm tra sự phụ thuộc tuyến tính của từng cặp biến với nhau.

```{r}
paged_table(as.data.frame(cor(main_data)))
```

Dựng đồ thị mô tả sự tương quan giữa các cặp biến:

```{r}
contTab = subset(main_data, select = colnames(main_data))
pairs(contTab)
```

# Xây dựng mô hình hồi quy bội
## Định nghĩa và ký hiệu cho mô hình

## Ước lượng tham số
Tính ra các hệ số của mô hình

```{r}
model <- lm(new_deaths ~ new_cases + new_tests + hosp_patients + positive_rate, 
            data = main_data)
summary(model)
# In ra cac he so cua mo hinh
paged_table(as.data.frame(t(model$coefficients)))

SSE <- (model$residuals ^ 2) %>% sum()
SSR <- ((model$fitted.values - mean(main_data$new_deaths)) ^ 2) %>% sum()
SST <- ((main_data$new_deaths - mean(main_data$new_deaths)) ^ 2) %>% sum()
table <- data.frame(SSE, SSR, SST)
# Print the table
paged_table(table)
```

## Ước lượng độ lệch chuẩn của sai số

Công thức tính phương sai của sai số:

$${\hat{\sigma}}^2 = \dfrac{SSE}{n-(k+1)}$$

Với $n$ là số lượng quan sát và $k$ là số lượng tham số hồi quy.

Tính độ lệch chuẩn của sai số:
```{r}
error_sd <- sqrt(SSE / (nrow(main_data) - 5))
print(error_sd)
```
## Xác định hệ số $R^2$ (Hệ số xác định)

Hệ số xác định (Coefficient of Determination) là tỷ lệ của tổng sự
biến thiên trong biến phụ thuộc gây ra bởi sự biến thiên của các biến
độc lập (biến giải thích) so với tổng sự biến thiên toàn phần. Hệ số
xác định thường được gọi là $R$. Công thức tính:

$$R^2 = \dfrac{SSR}{SST}$$

```{r}
R2 <- SSR / SST
print(paste0("R^2 = ", R2))
```

Hệ số $R^2$ hiệu chỉnh được tính bằng công thức sau:

$$R^2_{adjusted} = 1 - \dfrac{n-1}{n-(k+1)}(1-R^2)$$

```{r}
R2_adjusted <- 1 - (nrow(main_data) - 1)/(nrow(main_data) - 5)*(1-R2) 
print(paste0("Adjusted R^2 = ", R2_adjusted))
```

## Xác định khoảng tin cậy của các hệ số hồi quy

## Kiểm định giả thuyết cho các hệ số hồi quy

## Kiểm định đường hồi quy và các hệ số hồi quy

## Xác định khoảng tin cậy của giá trị trung bình của $Y$ khi $x=x_0$

## Xác định khoảng tin cậy của các giá trị dự đoán

## Kiểm định sự phù hợp của mô hình hồi quy tuyến tính